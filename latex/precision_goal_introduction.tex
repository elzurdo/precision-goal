
Empirical hypothesis testing is foundational to scientific progress, enabling researchers to assess how well a sample represents an underlying truth. A central challenge in this process is determining when enough data has been collected to make a reliable decision, especially as the accuracy of statistical assessments depends heavily on sample size. As emphasized by \cite{maxwell1984}, careful planning for statistical power and precision is essential to avoid biased inference and ensure meaningful results.

Sequential hypothesis testing offers a flexible alternative to fixed-sample designs by allowing data to be evaluated as it accumulates, with stopping and decision criteria guiding when to conclude data collection. This approach is widely used in fields such as clinical trials, quality control, A/B testing, and financial monitoring, offering potential benefits in efficiency, timeliness, and ethical considerations.

However, sequential analysis introduces important trade-offs. While it can reduce resource use and speed up decision-making, it also increases the risk of biased outcomes if stopping rules are not carefully chosen. In particular, commonly used Frequentist and Bayesian stopping criteria—such as p-value thresholds or posterior-based heuristics (e.g., HDI+ROPE, Bayes Factors)—can lead to confirmation bias, especially when stopping is triggered by extreme or unrepresentative samples. This phenomenon, known as early peaking, can result in premature and biased conclusions.

To address this, \cite{kruschke2015doing}—building on the foundational insight of \cite{maxwell1984}—advocated for using a predetermined target for posterior precision as a stopping rule, decoupling the decision to stop from the decision to accept or reject the null hypothesis. This ``Precision is the Goal'' (PitG) method eliminates bias in dichotomous outcome sampling. However, our analysis reveals a subtle but important limitation: when the null hypothesis is true, PitG often yields a high rate of inconclusive results, rather than correctly accepting the null.

In this paper, we propose an enhanced approach—``Enhanced Precision is the Goal'' (ePitG)—which requires that both the precision and decision criteria be met simultaneously. This more conservative rule substantially reduces the rate of inconclusive outcomes, with only a moderate increase in average sample size. We demonstrate that ePitG is especially effective when the null hypothesis is true, while remaining nearly indistinguishable from PitG in scenarios where the null can be strongly rejected.

Our results, based on simulations with dichotomous data, provide practical guidance for researchers seeking to balance efficiency, bias, and conclusiveness in sequential hypothesis testing. We also provide analytical insights, code, and tools to facilitate adoption of the method in applied settings.

