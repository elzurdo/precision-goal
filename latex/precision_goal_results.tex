We begin with a detailed examination of the fair coin case to establish the problem and
proposed solution ($\theta_{\rm null}=0.5$).
We then present general trends across the full range of $\theta_{\rm true}$ values 
which encompasses the ROPE and its boundaries. Detailed analyses of $\theta_{\rm true}=0.6$ and $\theta_{\rm true}=0.57$
scenarios are provided in Appendix \ref{sec:binomial_appendix}.

\subsection{Fair Coin ($\theta_{\rm true}=0.5$)}\label{sec:fair_coin}

Figure \ref{fig:iterations} presents the results of a hand-picked fair coin experiment.\footnote{This figure is similar to the top panels in \cite{kruschke2015doing} Figures 13.4 and 13.5. \textcolor{red}{\textbf{[TODO: provide the exact sequence]}}}
It was chosen to highlight potential stark differences in outcomes between the three algorithms.
Note that the posteriors shown in Figure \ref{fig:posteriors} correspond to three specific iterations of this single experiment.

As seen in Figure \ref{fig:iterations}, at iteration 126 (marked as a vertical red dashed line), the 95\% HDI of the \textit{HDI+ROPE} algorithm falls fully outside the ROPE, causing it to confidently---though incorrectly---reject $\theta_{\rm null}$.

In contrast, the \textit{Precision is the Goal} (PitG) stop criterion is met at iteration 598 (marked as the first pair of purple dots), when the HDI width becomes narrower than the precision goal of 0.08. However, because the HDI still straddles the ROPE boundary, the decision is inconclusive.

Finally, for \textit{Enhanced Precision is the Goal} (ePitG), the stop criterion is only
met at iteration 804 (marked as the green vertical line), 
when the HDI satisfies both conditions: it is narrower than the precision goal \textit{and} falls fully within the ROPE.
This results in a correct acceptance of $\theta_{\rm null}$.

\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{cherry_iterations.png}
  \caption{Hand-picked fair coin sample demonstrating variate outcomes by stop criterion. The vertical axis is the cumulative success rate at each iteration. The gray band is the 95\% HDI of each posterior. Highlighted iterations indicate stop triggers: Vertical red dashed lines = Reject $\theta_{\rm null}$; Vertical green solid lines = Accept $\theta_{\rm null}$. Purple dots indicate when the precision goal is achieved. Note: HDI+ROPE stops at iteration 126 (Recall top panel of Figure \ref{fig:posteriors}), PitG stops at iteration 598 (first purple dot; middle panel of Figure \ref{fig:posteriors}), and ePitG stops at iteration 804 (green line; bottom panel of Figure \ref{fig:posteriors}). ROPE boundaries are dashed horizontal lines.}
  \label{fig:iterations}
\end{figure}

We expand this analysis to $M=2,000$ experiments, displaying outcomes in Figures
\ref{fig:fair_iter_vs_rate}, \ref{fig:fair_decisions}
and summarizing key statistics in Tables \ref{tab:fair_overall}, \ref{tab:fair_conclusive}.


Figure \ref{fig:fair_iter_vs_rate} displays results of both individual experiments and their aggregated statistics,
with a focus on the distribution of stop iterations $N$ and success rates at the stop iteration $\hat{\theta}(N)$.\footnote{This visual is inspired by \cite{kruschke2015doing}, Figure 13.6.} 

\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{fair_experiments_iter_vs_rate.png}
  \caption{Outcomes of 2,000 experiments. Histograms and scatter plot are color coded by algorithm. The binning of the histograms vary by algorithm to best visualise the distribution of results.
  Bottom panel: histograms of stop iterations $N$.
  Left panel: histograms of observed success rate $\hat{\theta}(N)$ at the iteration when the stop criterion is met.
  Main panel: scatter plot of $\hat{\theta}(N)$. Each symbol represents individual experiment stops;
  Red squares: HDI+ROPE.
  Blue circles: PitG. Green Xs: ePitG.
  Solid line: $\theta_{\rm true}$.
  Dashed lines: ROPE boundaries. The vertical dashed line indicates the expected stop iteration for PitG (calculated by Equation \ref{eq:pitg_stop_iteration}).
  Note that whereas the scatter plots show the trends this histograms visualise where most of the results are distributed.
  }
  \label{fig:fair_iter_vs_rate}
\end{figure}

We notice that the HDI+ROPE (red squares) yields a wide range of stop iterations and success rates,
with a significant portion of results falling outside the ROPE, leading to incorrect rejections of $\theta_{\rm null}$.
Its distribution of $N$ shows both a skewness towards early stopping at $\sim 400$, much
earlier than the precision stop criterion of $N_{\theta_{\rm true}}\sim 600$ (dashed vertical line), and a long tail extending to later iterations.

In contrast, PitG (blue circles) consistently stops around iteration $N_{\theta_{\rm true}}$
with success rates clustered around $\theta_{\rm true}=0.5$.
However, many of these stops occur when the HDI straddles the ROPE boundary, resulting in a high rate of inconclusive decisions (see Figure \ref{fig:fair_decisions} and Table \ref{tab:fair_overall}).
ePitG (green Xs) shows a narrower $\hat{\theta}(N)$ distribution than PitG but extends to later iterations,
achieving more conclusive results while maintaining unbiased estimates.

Figure \ref{fig:fair_decisions} foceses our attention to the distrbituion of decisions
made up to (and including) each iteration with the three discussed options: 
reject $\theta_{\rm null}$ (red dashed line), accept $\theta_{\rm null}$ (green solid line),
and inconclusive (gray dot-dashed line).
For each panel the sum of these proportions is 100\%.\footnote{Display inspired by top panels of Figure 13.6 in \cite{kruschke2015doing}.}

\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{fair_experiment_decision_rates.png}
  \caption{Cumulative distribution of decisions.
  Left: HDI+ROPE. Middle: Precision is the Goal. Right: Enhanced Precision is the Goal.
  Vertical axis: Proportion of decisions where null hypothesis rejections are red dashed, acceptances are green solid, and inconclusive decisions are gray dot-dashed.
  At each iteration their sum is 100\% of the iteration decisions.}
  \label{fig:fair_decisions}
\end{figure}

The rejection rate of HDI+ROPE (left panel) quickly assymptotes at 6\%,
while the acceptance rate starts its increase at $N\sim 400$, reflecting a shift from incorrect rejections to correct acceptances as more data is collected.
The proportion of inconclusive decisions drops accordingly.

Both of the precision based methods demonstrate a correct zero rejection rate (middle and right panels), as they are designed to avoid false positives by requiring precision criteria to be met before making a decision.
For PitG (middle panel), the acceptance rate appears as a Heaviside step function, where it jumps at $N_{\theta_{\rm true}}$ to 36.7\%,
while the inconclusive rate drops to 63.3\% and stays there. 

The results of ePitG (right panel) appears to be a hybrid of the other two algorithms 
(as per its design), as it maintains the unbiased nature of PitG starting to accept
$\theta_{\rm null}$ at $N_{\theta_{\rm true}}$ while achieving a high conclusiveness rate
similar to HDI+ROPE, albeit with a more gradual transition from inconclusive to conclusive outcomes.


Table \ref{tab:fair_overall} summarises the overall conclusiveness rates and stop iterations
statistics for the 2,000 experiments. Table \ref{tab:fair_conclusive} focuses on the subset of conclusive experiments,
detailing the success rates at stopping points.

\begin{table}[h!]\label{tab:fair_overall}
  \begin{center}
  \begin{tabular}{c|c|c|c}
    \hline
    Algorithm &  Conclusive Rate  & $n_{\rm 50\%}$ & $n_{\rm 25\%} - n_{\rm 75\%}$\\
    \hline
    HDI+ROPE & 0.982 & 523 & 415-721  \\
    PitG     & \textcolor{red}{\textbf{0.367}}  & 599 & 598-599 \\
    ePitG    & \textcolor{green}{\textbf{0.977}}  & 627 & 598-794 \\
    \hline
  \end{tabular}
  \caption{Statistical summaries of 2,000 fair coin experiments (Figure \ref{fig:fair_iter_vs_rate}).
  Median stop iteration $n_{\rm 50\%}$;
  Interquartile range of stop iteration $n_{\rm 25\%} - n_{\rm 75\%}$;
  Median sample rate at stop $\hat{\theta}_{\rm 50\%}$;
  Interquartile range of sample rate at stop $\hat{\theta}_{\rm 25\%} - \hat{\theta}_{\rm 75\%}$.
 }
\end{center}
\end{table}

HDI+ROPE achieves a high conclusiveness rate of 98.2\%,
but at the cost of a 6.2\% false positive rate.
PitG has a much lower conclusiveness rate of 36.7\% with a zero false positives.
ePitG strikes a balance with a conclusiveness rate of 97.7\% and zero false positives,
albeit with a slightly higher median stop iteration compared to PitG.
The PitG stop iteration has a narrow IQR of $598-599$.
EPitG results in substantially more conclusive outcomes, with a median stop iteration of 627 and a wider IQR of $598-794$.
This can be quiatified as only a 4.7\% increase in the median stop iteration compared to PitG.\footnote{The ePitG $N$ 75th percentile is 794, which is a 32.5\% increase compared to the 599 of PitG. This highlights that while the median increase is small, there is a long tail of experiments that require significantly more samples to achieve conclusiveness with ePitG.}


\begin{table}[h!]\label{tab:fair_conclusive}
  \begin{center}
  \begin{tabular}{c|c|c|c|c|c}
    \hline
    Algorithm & Conclusive & Acceptence Rate & Rejection Rate &  $\hat{\theta}_{\rm 50\%}$ & $\hat{\theta}_{\rm 25\%} - \hat{\theta}_{\rm 75\%}$\\
    \hline
    HDI+ROPE & 1964 & 0.938 & \textcolor{red}{\textbf{0.062}} & 0.5000 & 0.4919-0.5075 \\
    PitG     &  \textcolor{red}{\textbf{734}} & 1     & 0     & 0.5008 & 0.4958-0.5041 \\
    ePitG    & 1953 & 1     & 0     & 0.5008 & 0.4895-0.5105\\
    \hline
  \end{tabular}
  \caption{Statistical summaries of a subset of fair coin experiments that resulted in conclusive outcomes from those in Table \ref{tab:fair_overall}.
  Median sample rate at stop $\hat{\theta}_{\rm 50\%}$;
  Interquartile range of sample rate at stop $\hat{\theta}_{\rm 25\%} - \hat{\theta}_{\rm 75\%}$.
  Note:  The sum of the Acceptence and Rejection rates are 1 due to conditioning on conclusive experiments.
  }
\end{center}
\end{table}


As this binomial setup is well-defined, we observe trends that can be described analytically. We discuss this in Section \textcolor{red}{\textbf{[TK]}}, but note here that the expected stop iteration for Precision is the Goal is approximated by:
\begin{equation}\label{eq:pitg_stop_iteration}
n \approx \frac{4 z_{*}^2}{\rm{CI}^2}p(1-p) - 1
\end{equation}
where:
\begin{itemize}
  \item $p$ is the success rate. \textcolor{red}{\textbf{[TK: Perhaps this should be $\theta_{\rm true}$?]}}
  \item ${\rm CI}$ is the precision goal (here 0.08).
  \item $z_{*}$ is the critical value (e.g., $z_{0.05}=1.96$). \textcolor{red}{\textbf{[TK: confirm variable. For some reason I wote "E.g, for 95\% quantile of the standard normal distribution"]}}
\end{itemize}

For this fair coin instance ($p=0.5$), we obtain $n \approx 599.2$, indicated by the dashed vertical line in Figure \ref{fig:fair_iter_vs_rate}.

We next move on to examine the general trends across the full range of $\theta_{\rm true}$ values,
which encompasses the ROPE and its boundaries. \textcolor{red}{\textbf{[TK: Note to self - repetitive from above, revise ...]}}

\subsection{General Trends Across $\theta_{\rm true}$ Values}

We next examine trends of these algorithms when conducting the experiments between
$\theta_{\rm true}=0.5$ through $0.65$ at intervals of $0.1$. \footnote{Due to symmetry of the problem the results between $\theta_{\rm true}=0.35$ through $0.5$ would mirror the ones shown here.}
Assuming a null hypothesis of $\theta_{\rm true}=0.5$ we find that the PitG and ePitG
are effectively the same algorithm as they yields the same results. Below we demonstrate
where they differ.

\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{conclusive_rates.png}
  \caption{Conclusiveness Rates.
  }
  \label{fig:conclusiveness_rates}
\end{figure}

Figure \ref{fig:conclusiveness_rates} illustrates the conclusiveness rates of each
algorithm where the horizontal axis is the true success rate and the null hypothesis
is $\theta_{\rm null}=0.5$. 
As expected, all have a minimal extremum at the ROPE upper coundary of $\theta=0.55$ (vertical dashed line).
As seen in Figures TBD and TBD at $\theta_{\rm true}=0.5$ the HDI+ROPE and ePitG are nearly
100\% conclusive whereas PitG is less than 40\%. HDI+ROPE and ePitG assymptote
to 100\% conclusiveness again at $\theta_{\rm true}=0.6$, whereas for PitG this happens
at $\theta_{\rm true}=0.65$. Throughout HDI+ROPE is the most conclusive, however, it
is the most biased.




\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{success_by_truth_conclusive.png}
  \caption{Experiment success rates by true values.
  Left:  Interquartile ranges (IQR).The solid line is parity with $\theta_{\rm true}$. Dotted lines are the ROPE boundaries. Note that in the Inconclusive Experiments those of HDI+ROPE and ePitG are very narrow.
  Right: Deviations from the truth: Median minus $\theta_{\rm true}$.
  }
  \label{fig:success_by_truth_conclusive}
\end{figure}


tbd


\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{stop_conclusiveness_ratios.png}
  \caption{ePitG vs. PitG vs. iteration stop and conclusiveness rates.
  }
  \label{fig:stop_conclusiveness_ratios}
\end{figure}



Figure \ref{fig:success_by_truth} illustrates the biases of the algorithms.
In the left panels we demonstrate for all the experiments. We find it instrumentive
to split these results into two mutually exclusive subsets: conclusive experiments
(middle panels) and inconclusive (right panels).
In the top panels we visualise the interquartile ranges of each algorithm
and in the bottom panels the deviation of the medians from the true values. The ROPE
upper boundary is highlighted with a vertical dashed line to indicate an important
inflection point.



\begin{figure}[h!]
  \centering
  \includegraphics[width=1\textwidth]{success_by_truth.png}
  \caption{Success Rates Compared to True Rates.
  Left: Results for all experiments.
  Center: Results of subset conclusive experiments (for rates see Figure \ref{fig:conclusiveness_rates}).
  Right: Results of subset inconclusive experiments.
  Top:  Interquartile ranges (IQR).The solid line is parity with $\theta_{\rm true}$. Dotted lines are the ROPE boundaries. Note that in the Inconclusive Experiments those of HDI+ROPE and ePitG are very narrow.
  Bottom: Deviations from the truth: Median minus $\theta_{\rm true}$.
  }
  \label{fig:success_by_truth}
\end{figure}

The left panels show that the PitG yields unbiassed results. \cite{kruschke2015doing}
show this for $\theta_{\rm true}=0.5$ and $0.65$ and we show this for the full range.

If one differentiates between conclusive and inconclusive outcome the PitG yields
between $\hat{\theta}=0.55-0.63$ positively biassed results. The biases



The left panels demonstrate that when $\theta_{\rm true}=0.5$ all three algorithms,
when conclusive, yield unbiased outcomes. This was seen in Figure X and may be explained
due to the symmetric nature of this particular expriement. For other $\theta_{\rm true}$
values within the ROPE we see that, in the conclusive case, they, on average, bias towards
the null hypothesis $\theta_{\rm null}=0.5$ and hence correctly accept it.

The left panels demonstrate that even though HDI+ROPE is the most conclusive when
$\theta_{\rm true}$ is larger than the ROPE boundary it is much more biassed.
As explained in Section TBD this is due to outliers that happen to satisfy the location
condition without satisfying the precision. Even though this approach yields the
correct answer of rejecting the null hypothesis it raises concern of the quoted
result $\hat{\theta}$. When accounting for the precision objective we see that beyond
the ROPE boundary the PitG performs better than

\subsection{Extension to Continuous Data}

\textcolor{red}{\textbf{[TODO: Add continuous data results demonstrating method generalization]}}

